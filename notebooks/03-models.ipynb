{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37406feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "da2349c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv(r'C:\\Projects_ciência_dados\\DIABETES\\data\\processed\\y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38812b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45786e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Diabetes'], dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76836b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(r'C:\\Projects_ciência_dados\\DIABETES\\data\\processed\\y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e63bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sparse.load_npz(r'C:\\Projects_ciência_dados\\DIABETES\\data\\processed\\x_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31dc82e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = sparse.load_npz(r'C:\\Projects_ciência_dados\\DIABETES\\data\\processed\\x_test.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1679ecbd",
   "metadata": {},
   "source": [
    "#### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd807245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad723a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "bernoulli = BernoulliNB()\n",
    "bernoulli.fit(x_train, y_train)\n",
    "previsao_bernoulli = bernoulli.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4df96ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia bernoulli: 0.82\n"
     ]
    }
   ],
   "source": [
    "acuracia_bernoulli = accuracy_score(previsao_bernoulli, y_test)\n",
    "print(f\"Acurácia bernoulli: {acuracia_bernoulli}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b81b85ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.84      1338\n",
      "           1       0.83      0.77      0.80      1162\n",
      "\n",
      "    accuracy                           0.82      2500\n",
      "   macro avg       0.82      0.82      0.82      2500\n",
      "weighted avg       0.82      0.82      0.82      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(previsao_bernoulli,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916eb091",
   "metadata": {},
   "source": [
    "#### Árvores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd5ffd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {\n",
    "    \"max_depth\":[100, 200, 500],\n",
    "    \"min_samples_split\":[2,5,10],\n",
    "    \"min_samples_leaf\":[1,5,10],\n",
    "    \"criterion\":[\"gini\", \"entropy\", \"log_loss\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6708c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2482afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc0ba8",
   "metadata": {},
   "source": [
    "#### Grid trabalha com dataset completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1c7cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=parametros)\n",
    "grid.fit(x_train, y_train)\n",
    "melhores_parametros = grid.best_params_\n",
    "melhor_resultado = grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20cfea14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 500, 'min_samples_leaf': 1, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "print(melhores_parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "613ddc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8242666666666667\n"
     ]
    }
   ],
   "source": [
    "print(melhor_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c16e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol = DecisionTreeClassifier()\n",
    "arbol.fit(x_train,y_train)\n",
    "previsao_arbol = arbol.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1035a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9884\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(previsao_arbol,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3a3d5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1411\n",
      "           1       0.99      0.99      0.99      1089\n",
      "\n",
      "    accuracy                           0.99      2500\n",
      "   macro avg       0.99      0.99      0.99      2500\n",
      "weighted avg       0.99      0.99      0.99      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(previsao_arbol,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e758b",
   "metadata": {},
   "source": [
    "#### Profundidade da árvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0507e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol.get_depth()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849660c",
   "metadata": {},
   "source": [
    "#### Numero de folhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45a19880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(582)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol.get_n_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "512bdae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.tree._tree.Tree at 0x2cd8b4a8d50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arbol.tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b3d02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_array = x_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09b5bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_DF = pd.DataFrame(x_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a458f0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1870</th>\n",
       "      <th>1871</th>\n",
       "      <th>1872</th>\n",
       "      <th>1873</th>\n",
       "      <th>1874</th>\n",
       "      <th>1875</th>\n",
       "      <th>1876</th>\n",
       "      <th>1877</th>\n",
       "      <th>1878</th>\n",
       "      <th>1879</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000001</td>\n",
       "      <td>2.308478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.940823</td>\n",
       "      <td>5.801497</td>\n",
       "      <td>6.415032</td>\n",
       "      <td>3.081867</td>\n",
       "      <td>2.519966</td>\n",
       "      <td>2.461312</td>\n",
       "      <td>3.917476</td>\n",
       "      <td>4.321749</td>\n",
       "      <td>2.000196</td>\n",
       "      <td>2.00109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000001</td>\n",
       "      <td>2.308478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.817569</td>\n",
       "      <td>5.163332</td>\n",
       "      <td>5.416465</td>\n",
       "      <td>4.822296</td>\n",
       "      <td>4.757269</td>\n",
       "      <td>3.508432</td>\n",
       "      <td>3.505110</td>\n",
       "      <td>5.160423</td>\n",
       "      <td>2.000196</td>\n",
       "      <td>2.00109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.308478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.715192</td>\n",
       "      <td>6.091572</td>\n",
       "      <td>3.568303</td>\n",
       "      <td>4.767263</td>\n",
       "      <td>2.311969</td>\n",
       "      <td>0.525492</td>\n",
       "      <td>4.810935</td>\n",
       "      <td>2.785344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.308478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.740967</td>\n",
       "      <td>4.815243</td>\n",
       "      <td>3.812708</td>\n",
       "      <td>3.226329</td>\n",
       "      <td>3.245290</td>\n",
       "      <td>3.029307</td>\n",
       "      <td>4.261114</td>\n",
       "      <td>2.130872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000001</td>\n",
       "      <td>2.308478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.400434</td>\n",
       "      <td>3.596928</td>\n",
       "      <td>4.378329</td>\n",
       "      <td>2.841096</td>\n",
       "      <td>5.026599</td>\n",
       "      <td>0.653001</td>\n",
       "      <td>5.292028</td>\n",
       "      <td>4.930171</td>\n",
       "      <td>2.000196</td>\n",
       "      <td>2.00109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000001</td>\n",
       "      <td>2.308478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.664366</td>\n",
       "      <td>4.815243</td>\n",
       "      <td>6.494172</td>\n",
       "      <td>4.801658</td>\n",
       "      <td>5.170597</td>\n",
       "      <td>1.050984</td>\n",
       "      <td>3.298927</td>\n",
       "      <td>3.519358</td>\n",
       "      <td>2.000196</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>2.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.308478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.251406</td>\n",
       "      <td>6.845767</td>\n",
       "      <td>4.231686</td>\n",
       "      <td>3.955521</td>\n",
       "      <td>2.754630</td>\n",
       "      <td>2.248797</td>\n",
       "      <td>3.436382</td>\n",
       "      <td>2.728130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000001</td>\n",
       "      <td>2.308478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.638590</td>\n",
       "      <td>4.409138</td>\n",
       "      <td>6.889874</td>\n",
       "      <td>2.813579</td>\n",
       "      <td>2.645298</td>\n",
       "      <td>1.236452</td>\n",
       "      <td>3.367654</td>\n",
       "      <td>4.575724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>2.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.308478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.791794</td>\n",
       "      <td>5.975542</td>\n",
       "      <td>5.344308</td>\n",
       "      <td>5.173134</td>\n",
       "      <td>2.087972</td>\n",
       "      <td>1.499198</td>\n",
       "      <td>3.161472</td>\n",
       "      <td>5.481379</td>\n",
       "      <td>2.000196</td>\n",
       "      <td>2.00109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>2.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.308478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.864221</td>\n",
       "      <td>6.497677</td>\n",
       "      <td>5.442070</td>\n",
       "      <td>2.669117</td>\n",
       "      <td>4.543939</td>\n",
       "      <td>3.620486</td>\n",
       "      <td>4.536024</td>\n",
       "      <td>3.724491</td>\n",
       "      <td>2.000196</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 1880 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3     4     5     6     7     8     \\\n",
       "0     0.000000  2.000001  2.308478  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "1     0.000000  2.000001  2.308478  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "2     0.000000  2.000001  0.000000  2.308478   0.0   0.0   0.0   0.0   0.0   \n",
       "3     2.000001  0.000000  2.308478  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "4     0.000000  2.000001  2.308478  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "...        ...       ...       ...       ...   ...   ...   ...   ...   ...   \n",
       "7495  0.000000  2.000001  2.308478  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "7496  2.000001  0.000000  0.000000  2.308478   0.0   0.0   0.0   0.0   0.0   \n",
       "7497  0.000000  2.000001  2.308478  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "7498  2.000001  0.000000  2.308478  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "7499  2.000001  0.000000  2.308478  0.000000   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "      9     ...      1870      1871      1872      1873      1874      1875  \\\n",
       "0      0.0  ...  4.940823  5.801497  6.415032  3.081867  2.519966  2.461312   \n",
       "1      0.0  ...  6.817569  5.163332  5.416465  4.822296  4.757269  3.508432   \n",
       "2      0.0  ...  3.715192  6.091572  3.568303  4.767263  2.311969  0.525492   \n",
       "3      0.0  ...  6.740967  4.815243  3.812708  3.226329  3.245290  3.029307   \n",
       "4      0.0  ...  5.400434  3.596928  4.378329  2.841096  5.026599  0.653001   \n",
       "...    ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "7495   0.0  ...  6.664366  4.815243  6.494172  4.801658  5.170597  1.050984   \n",
       "7496   0.0  ...  4.251406  6.845767  4.231686  3.955521  2.754630  2.248797   \n",
       "7497   0.0  ...  3.638590  4.409138  6.889874  2.813579  2.645298  1.236452   \n",
       "7498   0.0  ...  3.791794  5.975542  5.344308  5.173134  2.087972  1.499198   \n",
       "7499   0.0  ...  4.864221  6.497677  5.442070  2.669117  4.543939  3.620486   \n",
       "\n",
       "          1876      1877      1878     1879  \n",
       "0     3.917476  4.321749  2.000196  2.00109  \n",
       "1     3.505110  5.160423  2.000196  2.00109  \n",
       "2     4.810935  2.785344  0.000000  0.00000  \n",
       "3     4.261114  2.130872  0.000000  2.00109  \n",
       "4     5.292028  4.930171  2.000196  2.00109  \n",
       "...        ...       ...       ...      ...  \n",
       "7495  3.298927  3.519358  2.000196  0.00000  \n",
       "7496  3.436382  2.728130  0.000000  2.00109  \n",
       "7497  3.367654  4.575724  0.000000  2.00109  \n",
       "7498  3.161472  5.481379  2.000196  2.00109  \n",
       "7499  4.536024  3.724491  2.000196  0.00000  \n",
       "\n",
       "[7500 rows x 1880 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9d7b1d",
   "metadata": {},
   "source": [
    "##### Serve para ver as features mais importantes, mas ele perdeu o nome das features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27a8fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame({\n",
    "    \"features\":x_train_DF.columns,\n",
    "    \"importancia\":arbol.feature_importances_\n",
    "}).sort_values(by=\"importancia\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "041e26ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>1869</td>\n",
       "      <td>0.230507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>1873</td>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>1876</td>\n",
       "      <td>0.002286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>1092</td>\n",
       "      <td>0.001967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>815</td>\n",
       "      <td>0.001917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      features  importancia\n",
       "1869      1869     0.230507\n",
       "1873      1873     0.003681\n",
       "1876      1876     0.002286\n",
       "1092      1092     0.001967\n",
       "815        815     0.001917"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69f86a8",
   "metadata": {},
   "source": [
    "#### Regressão logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e82ea1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5678d0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(x_train, y_train)\n",
    "previsao_logistic = logistic.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "84824579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8948\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(previsao_logistic,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d7b3263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91      1377\n",
      "           1       0.90      0.87      0.88      1123\n",
      "\n",
      "    accuracy                           0.89      2500\n",
      "   macro avg       0.89      0.89      0.89      2500\n",
      "weighted avg       0.89      0.89      0.89      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(previsao_logistic,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8c81b464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.8695999999999999)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_logistic = cross_val_score(logistic, x_train, y_train, cv=5)\n",
    "cross_logistic.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998882e4",
   "metadata": {},
   "source": [
    "#### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "941dc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "34c3320f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects_ciência_dados\\DIABETES\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "random = RandomForestClassifier()\n",
    "random.fit(x_train,y_train)\n",
    "previsao_random = random.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ccdda79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(previsao_random,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
